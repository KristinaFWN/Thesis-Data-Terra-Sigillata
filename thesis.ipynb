{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e524b1",
   "metadata": {},
   "source": [
    "# Thesis intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315ad7d3",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import tempun\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# Constants\n",
    "fabric_types = [\"esa\", \"esb\", \"esc\", \"esd\", \"its\", \"arsw\", \"lrd\", \"lrc\"]\n",
    "\n",
    "chronological_lower_date = \"standard_typo_chronological_lower_date\"\n",
    "chronological_upper_date = \"standard_typo_chronological_upper_date\"\n",
    "\n",
    "deposit_lower_date = \"deposit_lower_date\"\n",
    "deposit_upper_date = \"deposit_upper_date\"\n",
    "\n",
    "processed_data_path = \"./data/processed/processed.csv\"\n",
    "\n",
    "colors_dict = {\n",
    "    \"esa\": \"black\",\n",
    "    \"esb\": \"green\",\n",
    "    \"esc\": \"blue\",\n",
    "    \"esd\": \"red\",\n",
    "    \"its\": \"pink\",\n",
    "    \"arsw\": \"orange\",\n",
    "    \"lrd\": \"purple\",\n",
    "    \"lrc\": \"yellow\"\n",
    "}\n",
    "\n",
    "# Column names\n",
    "id_column = \"standard_form_id\"\n",
    "fabric_column = \"fabric_h1\"\n",
    "\n",
    "# Helper functions\n",
    "def create_date_dict_and_remove_empty(data, lower_date, upper_date):\n",
    "    minimum = data[lower_date].min()\n",
    "    maximum = data[upper_date].max()\n",
    "\n",
    "    date_dict = dict.fromkeys(range(int(minimum), int(maximum)), 0)\n",
    "\n",
    "    cleaned = data.dropna(subset=[lower_date])\n",
    "    cleaned = cleaned.dropna(subset=[upper_date])\n",
    "\n",
    "    return cleaned, date_dict\n",
    "\n",
    "\n",
    "def simulate_dates(data, lower_date, upper_date, size, column):\n",
    "    return data.apply(lambda row: tempun.model_date(\n",
    "        start=row[lower_date], stop=row[upper_date], size=size, count=row[column]), axis=1)\n",
    "\n",
    "\n",
    "def plot_graph(\n",
    "    dicts_of_df: Dict[str, pd.Series],\n",
    "    ax,\n",
    "    palette: List[str],\n",
    "    linewidth: int = 3,\n",
    "    linestyle: str = \"solid\",\n",
    "):\n",
    "\n",
    "    for key, colour in zip(dicts_of_df.keys(), palette):\n",
    "        data = dicts_of_df.get(key)\n",
    "        sns.lineplot(\n",
    "            data=data,\n",
    "            ax=ax,\n",
    "            label=key,\n",
    "            color=colour,\n",
    "            linewidth=linewidth,\n",
    "            linestyle=linestyle,\n",
    "        )\n",
    "\n",
    "\n",
    "def plot_and_save(observed, input_data, title, y_label, file_name, xlims):\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), dpi=300)\n",
    "\n",
    "    plot_graph(dicts_of_df=observed,\n",
    "               palette=colors_dict.values(),\n",
    "               ax=axs[0],\n",
    "               linewidth=2)\n",
    "\n",
    "    axs[0].set_xlim(xlims)\n",
    "    axs[1].set_xlim(xlims)\n",
    "\n",
    "    ax = axs.ravel()[0]\n",
    "    ax.set_ylim(0, None)\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.0f\"))\n",
    "    ax.set_xlabel(None)\n",
    "    ax.get_legend().remove()\n",
    "    ax.set_ylabel(None)\n",
    "    ax.set_xticklabels([int(i) if i != 0 else 1 for i in ax.get_xticks()])\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.985, 0.957), fontsize=8)\n",
    "\n",
    "    for fabric in fabric_types:\n",
    "        color = colors_dict[fabric]\n",
    "        filtered_input = input_data[input_data[\"fabric_h1\"]\n",
    "                                    == fabric][\"random_dates\"]\n",
    "        filtered_input = [el for el in filtered_input if type(el) != float]\n",
    "\n",
    "        tempun.kdeplot_from_randoms(filtered_input, ax=axs[1], color=color)\n",
    "\n",
    "    axs[1].set_ylim(0, None)\n",
    "    axs[1].yaxis.set_major_formatter(FormatStrFormatter(\"%.3f\"))\n",
    "    axs[1].set_xlabel(None)\n",
    "    axs[1].set_ylabel(None)\n",
    "\n",
    "    axs[0].set_ylabel(y_label)\n",
    "\n",
    "    fig.supxlabel(\"Year\")\n",
    "\n",
    "    axs[0].set_title(label=title, size=15, y=1.04)\n",
    "    axs[1].set_title(label=f\"Simulated {title}\", size=15, y=1.04)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./data/figures/{file_name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a7405b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb1c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue = pd.read_csv(\"./data/ICRATES_CATALOGUE.csv\",\n",
    "                        usecols=[\n",
    "                            \"ICRATES_ID\", \"Deposit_ID\", \"Location_ID\",\n",
    "                            \"Fabric_ID\", \"Fabric\", \"Standard_Form_ID\",\n",
    "                            \"Standard_Form_Publication_Uncertain\", \"Standard_Form_ICRATES\",\n",
    "                        ],\n",
    "                        encoding=\"latin-1\")\n",
    "\n",
    "deposit = pd.read_csv(\"./data/ICRATES_DEPOSIT.csv\",\n",
    "                      usecols=[\n",
    "                          \"Deposit_ID\", \"Lower_Date\", \"Upper_Date\",\n",
    "                      ],\n",
    "                      encoding=\"latin-1\")\n",
    "deposit.rename(columns={\"Lower_Date\": deposit_lower_date,\n",
    "               \"Upper_Date\": deposit_upper_date}, inplace=True)\n",
    "\n",
    "standard = pd.read_csv(\"./data/ICRATES_STANDARD_FORM.csv\", encoding=\"latin-1\")\n",
    "fabric = pd.read_csv(\"./data/fabric_h1.csv\", sep=\";\")\n",
    "\n",
    "data = pd.merge(catalogue, deposit, on=\"Deposit_ID\", how=\"left\")\n",
    "data = pd.merge(data, fabric, left_on=\"Fabric\", right_on=\"fabric\", how=\"left\")\n",
    "data = data.drop([\"Fabric\"], axis=1)\n",
    "\n",
    "data = pd.merge(data, standard, on=\"Standard_Form_ID\", how='left')\n",
    "\n",
    "data.columns = data.columns.str.lower()\n",
    "data[fabric_column] = data[fabric_column].replace({\"CRSW\": \"LRD\", \"PRSW\": \"LRC\"})\n",
    "\n",
    "data[fabric_column] = data[fabric_column].apply(lambda x: str(x).lower())\n",
    "data = data[data[fabric_column].isin(fabric_types)]\n",
    "\n",
    "data.to_csv(processed_data_path, index=False)\n",
    "\n",
    "# Clean up values to not use space\n",
    "catalogue = None\n",
    "deposit = None\n",
    "standard = None\n",
    "fabric = None\n",
    "data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240758b5",
   "metadata": {},
   "source": [
    "## Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a952b",
   "metadata": {},
   "source": [
    "### Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a929f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_column = \"frequency\"\n",
    "summed_column = \"summed\"\n",
    "\n",
    "processed = pd.read_csv(processed_data_path, encoding=\"latin-1\", usecols=[\n",
    "    id_column, chronological_lower_date, chronological_upper_date,\n",
    "    deposit_lower_date, deposit_upper_date, fabric_column\n",
    "], )\n",
    "\n",
    "processed[frequency_column] = 1\n",
    "\n",
    "\n",
    "def calculate_summed_frequency(lower_date, upper_date):\n",
    "    data_ = processed.groupby([id_column, lower_date, upper_date, fabric_column])[\n",
    "        frequency_column].sum()\n",
    "\n",
    "    data_ = data_.reset_index()\n",
    "\n",
    "    for _ in range(len(data_)):\n",
    "        data_[summed_column] = data_[frequency_column] / \\\n",
    "            (data_[upper_date] - data_[lower_date])\n",
    "\n",
    "    return data_\n",
    "\n",
    "\n",
    "def calculate_frequency(summed, lower_date, upper_date):\n",
    "    cleaned, date_dict = create_date_dict_and_remove_empty(\n",
    "        summed, lower_date, upper_date)\n",
    "\n",
    "    for row in range(len(cleaned)):\n",
    "        for year in range(\n",
    "            cleaned[lower_date].astype(\n",
    "                int).iloc[row], cleaned[upper_date].astype(int).iloc[row]\n",
    "        ):\n",
    "            date_dict[year] += cleaned[summed_column].iloc[row]\n",
    "\n",
    "    series = pd.Series(date_dict, name=\"Frequency\")\n",
    "    series.index.name = \"Year\"\n",
    "    series.reset_index()\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def calculate_frequency_data(lower_date, upper_date):\n",
    "    summed_frequencies = calculate_summed_frequency(\n",
    "        lower_date, upper_date)\n",
    "    freq_dictionary = {}\n",
    "    for fabric in fabric_types:\n",
    "        freq_dictionary[fabric.upper()] = calculate_frequency(\n",
    "            summed_frequencies[fabric == summed_frequencies[fabric_column]], lower_date, upper_date)\n",
    "    return freq_dictionary\n",
    "\n",
    "\n",
    "def full_frequency(title, file_name, lower_date, upper_date):\n",
    "\n",
    "    processed[\"random_dates\"] = simulate_dates(\n",
    "        processed, lower_date, upper_date, 100, frequency_column)\n",
    "\n",
    "    plot_and_save(calculate_frequency_data(lower_date, upper_date), processed, title,\n",
    "                  \"Frequency\", file_name, [-300, 800])\n",
    "\n",
    "\n",
    "# Type Dates\n",
    "full_frequency(\"Type Dates\", \"type_dates_freq\",\n",
    "               chronological_lower_date, chronological_upper_date)\n",
    "\n",
    "# Deposit Dates\n",
    "full_frequency(\"Deposit dates\", \"deposit_dates_freq\",\n",
    "               deposit_lower_date, deposit_upper_date)\n",
    "\n",
    "# Clean up values to not use space\n",
    "processed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_id_column = \"location_id\"\n",
    "\n",
    "processed = pd.read_csv(processed_data_path, encoding=\"latin-1\", usecols=[\n",
    "    id_column, chronological_lower_date, chronological_upper_date,\n",
    "    deposit_lower_date, deposit_upper_date, fabric_column, location_id_column\n",
    "])\n",
    "\n",
    "# Code breaks if location id is None, so need to replace with 1 \n",
    "processed[location_id_column] = processed[location_id_column].apply(\n",
    "    lambda x: int(x) if x == x else 1)\n",
    "\n",
    "\n",
    "def calculate_site_count(group, lower_date, upper_date):\n",
    "    cleaned, date_dict = create_date_dict_and_remove_empty(\n",
    "        group, lower_date, upper_date)\n",
    "\n",
    "    for date_entry in date_dict:\n",
    "\n",
    "        result_list = []\n",
    "\n",
    "        for row in range(len(cleaned)):\n",
    "            if (\n",
    "                cleaned[lower_date].astype(int).iloc[row]\n",
    "                <= date_entry\n",
    "                <= cleaned[upper_date].astype(int).iloc[row]\n",
    "            ):\n",
    "                result_list.append(cleaned[location_id_column].iloc[row])\n",
    "\n",
    "        length = len(result_list)\n",
    "\n",
    "        if length == 0:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            flat_list = [item for sublist in result_list for item in sublist]\n",
    "\n",
    "            date_dict[date_entry] = len(set(flat_list))\n",
    "\n",
    "    series = pd.Series(date_dict, name=\"Site Count\")\n",
    "    series.index.name = \"Year\"\n",
    "    series.reset_index()\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def site_count_calculation(lower_date, upper_date):\n",
    "    precleaned = processed.dropna(subset=[lower_date, upper_date])\n",
    "    groupedby = precleaned.groupby([id_column, lower_date, upper_date, fabric_column])[\n",
    "        location_id_column].apply(list)\n",
    "    groupedby = groupedby.reset_index()\n",
    "\n",
    "    site_count_dictionary = {}\n",
    "    for fabric in fabric_types:\n",
    "        site_count_dictionary[fabric.upper()] = calculate_site_count(\n",
    "            groupedby[fabric == groupedby[fabric_column]], lower_date, upper_date)\n",
    "    return site_count_dictionary\n",
    "\n",
    "\n",
    "def full_site_count(title, file_name, lower_date, upper_date):\n",
    "    processed[\"random_dates\"] = processed.dropna(subset=[lower_date, upper_date]).apply(lambda row: tempun.model_date(\n",
    "        start=row[lower_date], stop=row[upper_date], size=100, count=1), axis=1)\n",
    "\n",
    "    plot_and_save(site_count_calculation(lower_date, upper_date), processed, title,\n",
    "                  \"Site Count\", file_name, [-300, 800])\n",
    "\n",
    "\n",
    "# Type Dates\n",
    "full_site_count(\"Type Dates\", \"type_dates_site_count\",\n",
    "                chronological_lower_date, chronological_upper_date)\n",
    "\n",
    "# Deposit Dates\n",
    "full_site_count(\"Deposit dates\", \"deposit_dates_site_count\",\n",
    "                deposit_lower_date, deposit_upper_date)\n",
    "\n",
    "# Clean up values to not use space\n",
    "processed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed = pd.read_csv(processed_data_path, encoding=\"latin-1\", usecols=[\n",
    "    id_column, chronological_lower_date, chronological_upper_date,\n",
    "    deposit_lower_date, deposit_upper_date, fabric_column, \"standard_form\"\n",
    "])\n",
    "\n",
    "# Code breaks if location id is None, so need to replace with zero\n",
    "# processed[location_id_column] = processed[location_id_column].apply(\n",
    "#   lambda x: int(x+0) if x == x else 0)\n",
    "\n",
    "\n",
    "def calculate_type_count(group, lower_date, upper_date):\n",
    "    cleaned, date_dict = create_date_dict_and_remove_empty(\n",
    "        group, lower_date, upper_date)\n",
    "\n",
    "    for date_entry in date_dict:\n",
    "\n",
    "        result_list = []\n",
    "\n",
    "        for row in range(len(cleaned)):\n",
    "            if (\n",
    "                cleaned[lower_date].astype(int).iloc[row]\n",
    "                <= date_entry\n",
    "                <= cleaned[upper_date].astype(int).iloc[row]\n",
    "            ):\n",
    "                result_list.append(cleaned[id_column].iloc[row])\n",
    "\n",
    "        length = len(result_list)\n",
    "\n",
    "        if length == 0:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            flat_list = [item for sublist in result_list for item in sublist]\n",
    "\n",
    "            date_dict[date_entry] = len(set(flat_list))\n",
    "\n",
    "    series = pd.Series(date_dict, name=\"Type Count\")\n",
    "    series.index.name = \"Year\"\n",
    "    series.reset_index()\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def type_count_calculation(lower_date, upper_date):\n",
    "    groupedby = processed.groupby([\"standard_form\", lower_date, upper_date, fabric_column])[\n",
    "        id_column].apply(list)\n",
    "    groupedby = groupedby.reset_index()\n",
    "\n",
    "    site_count_dictionary = {}\n",
    "    for fabric in fabric_types:\n",
    "        site_count_dictionary[fabric.upper()] = calculate_type_count(\n",
    "            groupedby[fabric == groupedby[fabric_column]], lower_date, upper_date)\n",
    "    return site_count_dictionary\n",
    "\n",
    "\n",
    "def full_type_count(title, file_name, lower_date, upper_date):\n",
    "    processed[\"random_dates\"] = processed.dropna(subset=[lower_date, upper_date]).apply(lambda row: tempun.model_date(\n",
    "        start=row[lower_date], stop=row[upper_date], size=100, count=1), axis=1)\n",
    "\n",
    "    plot_and_save(type_count_calculation(lower_date, upper_date), processed, title,\n",
    "                  \"Type Count\", file_name, [-300, 800])\n",
    "\n",
    "\n",
    "# Type Dates\n",
    "full_type_count(\"Type Dates\", \"type_dates_type_count\",\n",
    "                chronological_lower_date, chronological_upper_date)\n",
    "\n",
    "# Deposit Dates\n",
    "full_type_count(\"Deposit dates\", \"deposit_dates_type_count\",\n",
    "                deposit_lower_date, deposit_upper_date)\n",
    "\n",
    "# Clean up values to not use space\n",
    "processed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b2d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all datasets\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "processed = pd.read_csv(processed_data_path)\n",
    "processed[frequency_column] = 1\n",
    "\n",
    "freq_deposit = calculate_frequency_data(deposit_lower_date, deposit_upper_date)\n",
    "freq_chronological = calculate_frequency_data(\n",
    "    chronological_lower_date, chronological_upper_date)\n",
    "\n",
    "site_deposit = site_count_calculation(deposit_lower_date, deposit_upper_date)\n",
    "site_chronological = site_count_calculation(\n",
    "    chronological_lower_date, chronological_upper_date)\n",
    "\n",
    "type_deposit = type_count_calculation(deposit_lower_date, deposit_upper_date)\n",
    "type_chronological = type_count_calculation(\n",
    "    chronological_lower_date, chronological_upper_date)\n",
    "\n",
    "datasets = [freq_chronological, freq_deposit, site_chronological,\n",
    "            site_deposit, type_chronological, type_deposit]\n",
    "\n",
    "sns.set_style(\"white\", {\"font.family\": \"serif\",\n",
    "              \"font.serif\": \"Times New Roman\"})\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))\n",
    "\n",
    "axs[0, 0].set_xlim([-300, 700])\n",
    "axs[0, 1].set_xlim([-300, 700])\n",
    "axs[1, 0].set_xlim([-300, 700])\n",
    "axs[1, 1].set_xlim([-300, 700])\n",
    "axs[2, 0].set_xlim([-300, 700])\n",
    "axs[2, 1].set_xlim([-300, 700])\n",
    "\n",
    "for ax, df in zip(axs.ravel(), datasets):\n",
    "    plot_graph(dicts_of_df=df,\n",
    "               palette=[\"black\", \"green\", \"blue\", \"red\",\n",
    "                        \"pink\", \"orange\", \"purple\", \"yellow\"],\n",
    "               ax=ax,\n",
    "               linewidth=2)\n",
    "\n",
    "    ax.set_ylim(0, None)\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.0f\"))\n",
    "    ax.set_xlabel(None)\n",
    "    ax.get_legend().remove()\n",
    "    ax.set_ylabel(None)\n",
    "    ax.set_xticklabels([int(i) if i != 0 else 1 for i in ax.get_xticks()])\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.985, 0.957), fontsize=8)\n",
    "\n",
    "axs[0, 0].set_ylabel(\"Frequency\")\n",
    "axs[1, 0].set_ylabel(\"Site count\")\n",
    "axs[2, 0].set_ylabel(\"Type count\")\n",
    "\n",
    "axs[0, 0].set_title(label=\"Type dates\", size=15, y=1.04)\n",
    "axs[0, 1].set_title(label=\"Deposit dates\", size=15, y=1.04)\n",
    "\n",
    "axs[0, 0].text(-280, 29, \"A\", fontsize=25)\n",
    "axs[0, 1].text(-280, 21, \"B\", fontsize=25)\n",
    "axs[1, 0].text(-280, 146, \"C\", fontsize=25)\n",
    "axs[1, 1].text(-280, 27, \"D\", fontsize=25)\n",
    "axs[2, 0].text(-280, 241, \"E\", fontsize=25)\n",
    "axs[2, 1].text(-280, 169, \"F\", fontsize=25)\n",
    "\n",
    "fig.supxlabel(\"Year\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./data/figures/combined.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
